{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:21.417787Z","iopub.status.busy":"2023-05-27T02:00:21.417333Z","iopub.status.idle":"2023-05-27T02:00:37.809623Z","shell.execute_reply":"2023-05-27T02:00:37.808099Z","shell.execute_reply.started":"2023-05-27T02:00:21.417751Z"},"papermill":{"duration":13.875729,"end_time":"2023-05-08T06:10:55.254188","exception":false,"start_time":"2023-05-08T06:10:41.378459","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from konlpy) (4.9.2)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.10/site-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install konlpy  # 토큰화에 사용할 konlpy 라이브러리 설치"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:37.812036Z","iopub.status.busy":"2023-05-27T02:00:37.811659Z","iopub.status.idle":"2023-05-27T02:00:38.662142Z","shell.execute_reply":"2023-05-27T02:00:38.661140Z","shell.execute_reply.started":"2023-05-27T02:00:37.812003Z"},"papermill":{"duration":0.022219,"end_time":"2023-05-08T06:10:55.287013","exception":false,"start_time":"2023-05-08T06:10:55.264794","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os, random\n","from tqdm import tqdm # 진행도 시각화를 위한 라이브러리\n","from sklearn.linear_model import LogisticRegression\n","\n","seed=42\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","random.seed(seed)\n","np.random.seed(seed)"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.009253,"end_time":"2023-05-08T06:10:55.306186","exception":false,"start_time":"2023-05-08T06:10:55.296933","status":"completed"},"tags":[]},"source":["# 데이터 불러오기"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:38.664190Z","iopub.status.busy":"2023-05-27T02:00:38.663739Z","iopub.status.idle":"2023-05-27T02:00:39.642269Z","shell.execute_reply":"2023-05-27T02:00:39.640686Z","shell.execute_reply.started":"2023-05-27T02:00:38.664148Z"},"papermill":{"duration":0.863577,"end_time":"2023-05-08T06:10:56.179319","exception":false,"start_time":"2023-05-08T06:10:55.315742","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(149993, 2)\n","(49999, 1)\n"]}],"source":["train_data = pd.read_csv(\"/kaggle/input/2023-ml-project1/nsmc_train.csv\", index_col=0)\n","test_data = pd.read_csv(\"/kaggle/input/2023-ml-project1/nsmc_test.csv\", index_col=0)\n","print(train_data.shape)\n","print(test_data.shape)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:39.645487Z","iopub.status.busy":"2023-05-27T02:00:39.644832Z","iopub.status.idle":"2023-05-27T02:00:39.673803Z","shell.execute_reply":"2023-05-27T02:00:39.672562Z","shell.execute_reply.started":"2023-05-27T02:00:39.645453Z"},"papermill":{"duration":0.044922,"end_time":"2023-05-08T06:10:56.234099","exception":false,"start_time":"2023-05-08T06:10:56.189177","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>rating</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9324809</th>\n","      <td>배우들의 인생연기가 돋보였던... 최고의 드라마</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9305425</th>\n","      <td>아 혜리 보고싶다 ... 여군좀 ㅠ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5239110</th>\n","      <td>눈이 팅팅..... 정말 ,..... 대박이다......</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9148159</th>\n","      <td>캐슬린 터너의 보디는 볼만했다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6144938</th>\n","      <td>진짜 최고였다.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                  review  rating\n","id                                              \n","9324809       배우들의 인생연기가 돋보였던... 최고의 드라마       1\n","9305425              아 혜리 보고싶다 ... 여군좀 ㅠ       0\n","5239110  눈이 팅팅..... 정말 ,..... 대박이다......       1\n","9148159                 캐슬린 터너의 보디는 볼만했다       0\n","6144938                         진짜 최고였다.       1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:39.675655Z","iopub.status.busy":"2023-05-27T02:00:39.675196Z","iopub.status.idle":"2023-05-27T02:00:39.682650Z","shell.execute_reply":"2023-05-27T02:00:39.680948Z","shell.execute_reply.started":"2023-05-27T02:00:39.675623Z"},"papermill":{"duration":0.032904,"end_time":"2023-05-08T06:10:56.282527","exception":false,"start_time":"2023-05-08T06:10:56.249623","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["x_train = train_data[\"review\"]\n","y_train = np.array(train_data[\"rating\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.01003,"end_time":"2023-05-08T06:10:56.302834","exception":false,"start_time":"2023-05-08T06:10:56.292804","status":"completed"},"tags":[]},"source":["# 자연어 전처리\n","## \\[Empty Module #1\\] 데이터 전처리\n","### 데이터 전처리 수행\n","> 먼저, 리뷰를 분류하는데 도움이 되거나, 머신러닝 처리에 어려운 단어들을 제거해봅시다.\n","1. 아래 조건에 맞는 정규표현식을 작성하여 영어와 한글 문자를 제외한 특수문자나 이모지, 숫자 등을 제거해봅시다.\n","  - <mark>한글 문자(초성 제외), 영어 대문자, 영어 소문자, 띄어쓰기 이외의 문자를 제외</mark>하는 정규표현식 작성\n","2. 영어 단어의 경우 같은 단어들이 같은 토큰으로 분류될 수 있도록 <mark>대문자로 통일</mark>해줍니다."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:39.685800Z","iopub.status.busy":"2023-05-27T02:00:39.684837Z","iopub.status.idle":"2023-05-27T02:00:39.698623Z","shell.execute_reply":"2023-05-27T02:00:39.697434Z","shell.execute_reply.started":"2023-05-27T02:00:39.685759Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["안녕 HELLO반갑다\n"]}],"source":["import re\n","\n","def apply_regex(pattern, text):  # 정규표현식을 이용한 필터링 적용\n","    text = re.sub(pattern, \"\", text)  # 정규표현식 패턴에 맞는 값들을 텍스트에서 제거\n","    text = text.upper()# 영어들을 찾아 대문자로 치환하는 코드 작성\n","    return text\n","\n","text = \"안녕 Hello!!!:)ㅎㅎ반갑다.ㅠㅠ__\"\n","#pattern = '[^가-힣A-Za-z]'\n","pattern = '[^\\w\\s]|[ㄱ-ㅎ]|[ㅏ-ㅠ]|_'\n","output = apply_regex(pattern, text)\n","print(output)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:39.700652Z","iopub.status.busy":"2023-05-27T02:00:39.700290Z","iopub.status.idle":"2023-05-27T02:00:41.073386Z","shell.execute_reply":"2023-05-27T02:00:41.072151Z","shell.execute_reply.started":"2023-05-27T02:00:39.700623Z"},"papermill":{"duration":0.982216,"end_time":"2023-05-08T06:10:57.296264","exception":false,"start_time":"2023-05-08T06:10:56.314048","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/1444518553.py:18: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n","  x_train_preprocessed = [apply_regex(pattern, str(x[1])) for x in tqdm(x_train.iteritems(), total=len(x_train), desc=\"pre-processing data\")]\n","pre-processing data: 100%|██████████| 149993/149993 [00:01<00:00, 110794.84it/s]\n"]}],"source":["##########################################################################################\n","# Empty Module #1\n","# 입력: 자연어 상태의 리뷰 텍스트\n","# 출력: 한글(초성 제외), 영어 대문자, 띄어쓰기로만 구성된 텍스트 \n","# 입력 예시: \"안녕 Hello!!!:)ㅎㅎ반갑다.\"\n","# 출력 예시: \"안녕 HELLO반갑다\"\n","##########################################################################################\n","import re\n","\n","# 여기에 정규표현식 코드 작성\n","pattern = '[^\\w\\s]|[ㄱ-ㅎ]|[ㅏ-ㅣ]|_'\n","\n","def apply_regex(pattern, text):  # 정규표현식을 이용한 필터링 적용\n","    text = re.sub(pattern, \"\", text)  # 정규표현식 패턴에 맞는 값들을 텍스트에서 제거\n","    text = text.upper() # 영어들을 찾아 대문자로 치환하는 코드 작성\n","    return text\n","\n","x_train_preprocessed = [apply_regex(pattern, str(x[1])) for x in tqdm(x_train.iteritems(), total=len(x_train), desc=\"pre-processing data\")]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:41.075673Z","iopub.status.busy":"2023-05-27T02:00:41.075056Z","iopub.status.idle":"2023-05-27T02:00:41.084168Z","shell.execute_reply":"2023-05-27T02:00:41.082824Z","shell.execute_reply.started":"2023-05-27T02:00:41.075639Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'배우들의 인생연기가 돋보였던 최고의 드라마'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x_train_preprocessed[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.014265,"end_time":"2023-05-08T06:10:57.323679","exception":false,"start_time":"2023-05-08T06:10:57.309414","status":"completed"},"tags":[]},"source":["## \\[Empty Module #2\\] 단어 토큰화\n","### Open Korean Text(OKT)를 이용한 단어 토큰화(Tokenization)\n","- 한국어 자연어 처리 라이브러리인 konlpy의 OKT 래퍼를 통하여 문장을 단어로 토큰화해봅시다.\n","- 아래 도큐먼트를 참고하여 토큰화를 수행합니다.\n","  - <mark>이때, OKT 클래스의 특정 매개변수를 이용해 어근화를 진행해줍니다. (도큐먼트 참고)</mark>\n","- konlpy 도큐먼트: https://konlpy.org/ko/latest/api/konlpy.tag/#okt-class\n","- OKT 도큐먼트: https://github.com/open-korean-text/open-korean-text"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:41.086021Z","iopub.status.busy":"2023-05-27T02:00:41.085416Z","iopub.status.idle":"2023-05-27T02:00:42.621796Z","shell.execute_reply":"2023-05-27T02:00:42.620575Z","shell.execute_reply.started":"2023-05-27T02:00:41.085988Z"},"papermill":{"duration":1.373034,"end_time":"2023-05-08T06:10:58.70747","exception":false,"start_time":"2023-05-08T06:10:57.334436","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["##########################################################################################\n","# Empty Module #2\n","# 입력: 자연어 상태의 리뷰 데이터\n","# 출력: 토큰화와 과정을 거쳐 단어들의 리스트로 변환된 데이터\n","# 입력 예시: \"커피는 역시 학생회관 커피\"\n","# 출력 예시: [\"커피\", \"는\", \"역시\", \"학생\", \"회관\", \"커피\"]\n","##########################################################################################\n","from konlpy.tag import Okt\n","okt = Okt()\n","\n","def tokenize_words(sentence):\n","    sentence_tokenized = okt.morphs(sentence) # 여기에 코드 작성\n","    return sentence_tokenized"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:00:42.626659Z","iopub.status.busy":"2023-05-27T02:00:42.626259Z","iopub.status.idle":"2023-05-27T02:10:17.428241Z","shell.execute_reply":"2023-05-27T02:10:17.427047Z","shell.execute_reply.started":"2023-05-27T02:00:42.626625Z"},"papermill":{"duration":573.138395,"end_time":"2023-05-08T06:20:31.856663","exception":false,"start_time":"2023-05-08T06:10:58.718268","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizing data: 100%|██████████| 149993/149993 [09:34<00:00, 260.95it/s]\n"]}],"source":["# 약 10-15분 정도 소요됩니다. \n","x_train_tokenized = [tokenize_words(x) for x in tqdm(x_train_preprocessed, desc=\"tokenizing data\")]"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.226231,"end_time":"2023-05-08T06:20:32.313486","exception":false,"start_time":"2023-05-08T06:20:32.087255","status":"completed"},"tags":[]},"source":["## \\[Empty Module #3\\] 불용어 제거\n","- 조사를 비롯한 불용어들은 많은 횟수 등장하지만, 리뷰의 긍정과 부정 여부를 판단하는데는 도움이 되지 않습니다.\n","- 데이터에서 아래 리스트로 정의된 불용어들을 제거해줍니다."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:17.431057Z","iopub.status.busy":"2023-05-27T02:10:17.430239Z","iopub.status.idle":"2023-05-27T02:10:18.692369Z","shell.execute_reply":"2023-05-27T02:10:18.691138Z","shell.execute_reply.started":"2023-05-27T02:10:17.431012Z"},"papermill":{"duration":1.425199,"end_time":"2023-05-08T06:20:33.964564","exception":false,"start_time":"2023-05-08T06:20:32.539365","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']  #별다른 의미가 없는 불용어들\n","\n","def exclude_stopwords(text):\n","    text = [word for word in text if not word in stopwords] # 위 리스트에 포함된 불용어들을 제거하는 코드 작성\n","    return text\n","\n","x_train_stopwords_excluded = [exclude_stopwords(x) for x in x_train_tokenized]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:18.694795Z","iopub.status.busy":"2023-05-27T02:10:18.694323Z","iopub.status.idle":"2023-05-27T02:10:18.702417Z","shell.execute_reply":"2023-05-27T02:10:18.701056Z","shell.execute_reply.started":"2023-05-27T02:10:18.694751Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['배우', '인생', '연기', '돋보였던', '최고', '드라마']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["x_train_stopwords_excluded[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.227527,"end_time":"2023-05-08T06:20:34.416544","exception":false,"start_time":"2023-05-08T06:20:34.189017","status":"completed"},"tags":[]},"source":["## \\[Empty Module #4\\] 단어 임베딩\n","### 단어 임베딩 코드 구현\n","- 토큰화를 거쳐 분리된 단어들을 하나의 정수 값으로 매핑해주는 희소 표현법을 직접 구현해봅시다.\n","- 입력된 단어가 새로운 단어라면 새로운 정수 값을 할당하고, 이전에 등장한 단어라면 이전에 할당한 정수를 할당하는 함수를 작성합니다.\n","  - 단, <mark>테스트 데이터에 대해서는 새로운 단어가 등장하면 값을 할당하지 않습니다.</mark>"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:18.704989Z","iopub.status.busy":"2023-05-27T02:10:18.704411Z","iopub.status.idle":"2023-05-27T02:10:18.714479Z","shell.execute_reply":"2023-05-27T02:10:18.713533Z","shell.execute_reply.started":"2023-05-27T02:10:18.704958Z"},"papermill":{"duration":0.236545,"end_time":"2023-05-08T06:20:34.876645","exception":false,"start_time":"2023-05-08T06:20:34.6401","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["##########################################################################################\n","# Empty Module #4\n","# 입력: 단어 토큰화된 데이터\n","# 출력: 임베딩 과정을 거쳐, 각 단어가 하나의 실수 값으로 표현된 데이터\n","# 입력 예시: [\"커피\", \"역시\", \"학생\", \"회관\", \"커피\"]\n","# 출력 예시: [0, 1, 2, 3, 0]\n","##########################################################################################\n","\n","embedding_dict = dict()  # 단어 임베딩을 위한 딕셔너리\n","embedding_value = 0\n","\n","def embed_tokens(sentence_tokenized, mode):\n","    assert mode.upper() in [\"TRAIN\", \"TEST\"]\n","    global embedding_value\n","    \n","    sentence_embedded = list()\n","    for word in sentence_tokenized:\n","        # 코드 작성\n","        if mode.upper() in \"TRAIN\":\n","            if word not in embedding_dict.keys():\n","                embedding_dict[word] = embedding_value\n","                embedding_value += 1\n","            sentence_embedded.append(embedding_dict[word])\n","        elif mode.upper() in \"TEST\":\n","            if word in embedding_dict.keys():\n","                sentence_embedded.append(embedding_dict[word])\n","            \n","        \n","    \n","    return sentence_embedded"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:18.716972Z","iopub.status.busy":"2023-05-27T02:10:18.716240Z","iopub.status.idle":"2023-05-27T02:10:20.848749Z","shell.execute_reply":"2023-05-27T02:10:20.847523Z","shell.execute_reply.started":"2023-05-27T02:10:18.716930Z"},"papermill":{"duration":1.328669,"end_time":"2023-05-08T06:20:36.428533","exception":false,"start_time":"2023-05-08T06:20:35.099864","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["embedding data: 100%|██████████| 149993/149993 [00:02<00:00, 70853.96it/s]"]},{"name":"stdout","output_type":"stream","text":["[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19, 20, 21], [22, 4, 23]]\n","총 103790개의 단어가 임베딩되었습니다.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# 실행 시간이 제법 소요됩니다. 비정상이 아니니 걱정하지 않으셔도 됩니다.\n","x_train_embedded = [embed_tokens(x, mode=\"TRAIN\") for x in tqdm(x_train_stopwords_excluded, desc=\"embedding data\")]\n","print(x_train_embedded[:5])\n","print(\"총 %d개의 단어가 임베딩되었습니다.\"%(embedding_value))"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.284019,"end_time":"2023-05-08T06:20:36.936606","exception":false,"start_time":"2023-05-08T06:20:36.652587","status":"completed"},"tags":[]},"source":["## \\[Empty Module #5\\] 문장 벡터화\n","### Bag of Words 방법을 사용한 문장 벡터화\n","- 캐글 프로젝트 설명 페이지의 Bag of Words 방법 설명을 참고하여 Bag of Words 방법을 직접 구현해봅시다."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:20.850930Z","iopub.status.busy":"2023-05-27T02:10:20.850360Z","iopub.status.idle":"2023-05-27T02:10:20.859753Z","shell.execute_reply":"2023-05-27T02:10:20.858306Z","shell.execute_reply.started":"2023-05-27T02:10:20.850888Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[0, 1, 2, 3, 4, 5]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x_train_embedded[0]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:20.861844Z","iopub.status.busy":"2023-05-27T02:10:20.861237Z","iopub.status.idle":"2023-05-27T02:10:20.873167Z","shell.execute_reply":"2023-05-27T02:10:20.871936Z","shell.execute_reply.started":"2023-05-27T02:10:20.861804Z"},"trusted":true},"outputs":[{"data":{"text/plain":["103790"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["embedding_value"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:20.875160Z","iopub.status.busy":"2023-05-27T02:10:20.874634Z","iopub.status.idle":"2023-05-27T02:10:30.043874Z","shell.execute_reply":"2023-05-27T02:10:30.042673Z","shell.execute_reply.started":"2023-05-27T02:10:20.875117Z"},"papermill":{"duration":7.419859,"end_time":"2023-05-08T06:20:44.579436","exception":false,"start_time":"2023-05-08T06:20:37.159577","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["making BoW representation: 100%|██████████| 149993/149993 [00:09<00:00, 16383.99it/s]\n"]}],"source":["##########################################################################################\n","# Empty Module #5\n","# 입력: 임베딩 과정을 거친 데이터\n","# 출력: BoW 형태로 변환되어, M차원의 고정된 크기를 가진 벡터로 변환된 데이터\n","# 힌트: np.zeros((2, 3))는 [2, 3] 크기의 0으로 가득 찬 행렬을 생성합니다.\n","##########################################################################################\n","\n","M = embedding_value# 전체 단어의 수\n","\n","def to_BoW_representation(x):\n","    global M\n","    shape = (len(x), M) # BoW는 어떤 shape를 가져야 할까요?\n","    x_BoW = np.zeros(shape)\n","    for i in tqdm(range(len(x)), desc=\"making BoW representation\"):\n","        \n","        # 여기에 BoW 구현\n","        for j in range(len(x[i])):\n","            x_BoW[i][x[i][j]] += 1\n","\n","    return x_BoW\n","x_train_BoW = to_BoW_representation(x_train_embedded)"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.226259,"end_time":"2023-05-08T06:20:45.030446","exception":false,"start_time":"2023-05-08T06:20:44.804187","status":"completed"},"tags":[]},"source":["## \\[Empty Module #6\\] 차원 축소\n","- 우리가 만든 BoW는 수많은 리뷰에 등장하는 모든 단어들을 사용하여 만들어졌기 때문에, 엄청난 양의 단어들을 가지고 있습니다.\n","- 그러나, 실제로 영화 리뷰에 쓰이는 단어들은 이보다 적기 때문에, 많은 단어들이 전체 데이터에서 실제로는 한번도 등장하지 않거나, 매우 조금 등장하면서 공간을 차지하고 있을 것 입니다.\n","- 데이터의 크기를 줄여 머신러닝 모델이 중요한 정보에 집중할 수 있도록 해봅시다.\n","- <mark>학습 데이터에서 50번 미만으로 등장한 단어들을 제외</mark>해줍니다."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:30.045638Z","iopub.status.busy":"2023-05-27T02:10:30.045222Z","iopub.status.idle":"2023-05-27T02:10:30.053439Z","shell.execute_reply":"2023-05-27T02:10:30.052193Z","shell.execute_reply.started":"2023-05-27T02:10:30.045609Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[1., 1., 1., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["x_train_BoW"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:10:30.055558Z","iopub.status.busy":"2023-05-27T02:10:30.055140Z","iopub.status.idle":"2023-05-27T02:11:58.027683Z","shell.execute_reply":"2023-05-27T02:11:58.026390Z","shell.execute_reply.started":"2023-05-27T02:10:30.055520Z"},"papermill":{"duration":0.236099,"end_time":"2023-05-08T06:20:45.493465","exception":false,"start_time":"2023-05-08T06:20:45.257366","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["##########################################################################################\n","# Empty Module #6\n","# 입력: BoW 형태로 변환된 (N, M) 크기의 데이터\n","# 출력: 등장 빈도가 적은 단어들을 제외한 (N, m) 크기의 더 작은 데이터\n","##########################################################################################\n","\n","def exclude_rare_words(x, limit=50):\n","    # 코드 작성\n","    x_sum = x.sum(axis=0)\n","    indices = np.where(x_sum >= limit)[0]\n","    x_BoW = x[:, indices]\n","    return x_BoW, indices\n","\n","x_train_BoW_reduced, indices = exclude_rare_words(x_train_BoW, limit=50)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:11:58.029683Z","iopub.status.busy":"2023-05-27T02:11:58.029324Z","iopub.status.idle":"2023-05-27T02:11:58.035078Z","shell.execute_reply":"2023-05-27T02:11:58.033954Z","shell.execute_reply.started":"2023-05-27T02:11:58.029654Z"},"papermill":{"duration":7.501002,"end_time":"2023-05-08T06:20:53.222732","exception":false,"start_time":"2023-05-08T06:20:45.72173","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# 힌트\n","# 1. 먼저 전체 데이터에서 각 단어가 등장한 횟수를 세어보세요.\n","# 2. 그 다음, 등장 횟수가 50회 미만인 단어들을 찾습니다.\n","# 3. 해당 단어들을 데이터에서 제거하는 코드를 작성합니다.\n","# 4. 설계를 잘 하고 구현을 시작해야 어렵지 않습니다."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:11:58.036848Z","iopub.status.busy":"2023-05-27T02:11:58.036506Z","iopub.status.idle":"2023-05-27T02:11:58.048144Z","shell.execute_reply":"2023-05-27T02:11:58.046965Z","shell.execute_reply.started":"2023-05-27T02:11:58.036820Z"},"papermill":{"duration":12.114323,"end_time":"2023-05-08T06:21:05.627314","exception":false,"start_time":"2023-05-08T06:20:53.512991","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["원본 BoW 크기: (149993, 103790)\n","차원 축소 후 크기: (149993, 3724)\n"]}],"source":["# 여기에 코드 작성\n","\n","print(\"원본 BoW 크기:\", x_train_BoW.shape)\n","print(\"차원 축소 후 크기:\", x_train_BoW_reduced.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:11:58.050496Z","iopub.status.busy":"2023-05-27T02:11:58.050007Z","iopub.status.idle":"2023-05-27T02:11:58.063218Z","shell.execute_reply":"2023-05-27T02:11:58.061891Z","shell.execute_reply.started":"2023-05-27T02:11:58.050456Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[1., 1., 1., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["x_train_BoW_reduced"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:11:58.064726Z","iopub.status.busy":"2023-05-27T02:11:58.064384Z","iopub.status.idle":"2023-05-27T02:11:58.747790Z","shell.execute_reply":"2023-05-27T02:11:58.746653Z","shell.execute_reply.started":"2023-05-27T02:11:58.064700Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([ 5.,  2.,  4., ...,  6., 15.,  1.])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["x_train_BoW_reduced.sum(axis=1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.22558,"end_time":"2023-05-08T06:21:06.079455","exception":false,"start_time":"2023-05-08T06:21:05.853875","status":"completed"},"tags":[]},"source":["## \\[Empty Module #7\\]  분류 수행 및 제출: Bag of Words\n","- 이제 모든 문장이 고정된 크기 $m$ 차원의 벡터로 변환되었습니다.\n","- 원하는 모델을 사용하여, 각 문장의 영화에 대한 긍정적인 리뷰인지, 부정적인 리뷰인지 분류해봅시다.(Baseline 모델은 로지스틱 회귀입니다)\n","- 그 다음, 결과를 기록하여 Kaggle에 제출해봅시다!"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:11:58.750561Z","iopub.status.busy":"2023-05-27T02:11:58.749463Z","iopub.status.idle":"2023-05-27T02:11:58.756774Z","shell.execute_reply":"2023-05-27T02:11:58.755161Z","shell.execute_reply.started":"2023-05-27T02:11:58.750522Z"},"papermill":{"duration":43.097338,"end_time":"2023-05-08T06:21:49.406392","exception":false,"start_time":"2023-05-08T06:21:06.309054","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["##########################################################################################\n","# Empty Module #7\n","# 지금까지 전처리한 데이터로 분류를 수행하여, kaggle에 제출해봅시다.\n","# Baseline은 로지스틱 회귀입니다.\n","##########################################################################################\n","# 분류기 정의 및 학습 수행 코드 작성\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression(random_state=seed)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:11:58.760412Z","iopub.status.busy":"2023-05-27T02:11:58.759381Z","iopub.status.idle":"2023-05-27T02:12:59.507541Z","shell.execute_reply":"2023-05-27T02:12:59.505970Z","shell.execute_reply.started":"2023-05-27T02:11:58.760373Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(random_state=42)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(x_train_BoW_reduced, y_train)\n","#print(model.score(x_train_BoW_reduced))"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:12:59.516843Z","iopub.status.busy":"2023-05-27T02:12:59.515596Z","iopub.status.idle":"2023-05-27T02:17:23.719115Z","shell.execute_reply":"2023-05-27T02:17:23.717918Z","shell.execute_reply.started":"2023-05-27T02:12:59.516777Z"},"papermill":{"duration":275.661355,"end_time":"2023-05-08T06:26:28.190092","exception":false,"start_time":"2023-05-08T06:21:52.528737","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/1083764141.py:3: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n","  x_test_preprocessed = [apply_regex(pattern, str(x[1])) for x in tqdm(x_test.iteritems(), total=len(x_test), desc=\"pre-processing data\")]\n","pre-processing data: 100%|██████████| 49999/49999 [00:00<00:00, 101962.97it/s]\n","tokenizing data: 100%|██████████| 49999/49999 [04:06<00:00, 202.61it/s]\n","embedding data: 100%|██████████| 49999/49999 [00:00<00:00, 79737.15it/s]\n","making BoW representation: 100%|██████████| 49999/49999 [00:02<00:00, 18498.34it/s]\n"]}],"source":["# TEST 데이터를 전처리 (3분 정도걸림 주의)\n","x_test = test_data[\"review\"]\n","x_test_preprocessed = [apply_regex(pattern, str(x[1])) for x in tqdm(x_test.iteritems(), total=len(x_test), desc=\"pre-processing data\")]\n","x_test_tokenized = [tokenize_words(x) for x in tqdm(x_test_preprocessed, desc=\"tokenizing data\")]\n","x_test_stopwords_excluded = [exclude_stopwords(x) for x in x_test_tokenized]\n","x_test_embedded = [embed_tokens(x, mode=\"TEST\") for x in tqdm(x_test_stopwords_excluded, desc=\"embedding data\")]\n","x_test_BoW = to_BoW_representation(x_test_embedded)\n","x_test_BoW_reduced = x_test_BoW[:, indices]"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T02:17:23.720704Z","iopub.status.busy":"2023-05-27T02:17:23.720375Z","iopub.status.idle":"2023-05-27T02:17:23.947368Z","shell.execute_reply":"2023-05-27T02:17:23.945703Z","shell.execute_reply.started":"2023-05-27T02:17:23.720677Z"},"papermill":{"duration":1.030924,"end_time":"2023-05-08T06:26:29.528144","exception":false,"start_time":"2023-05-08T06:26:28.49722","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# TEST 데이터에 대한 예측 수행 코드 작성\n","y_test_pred = model.predict(x_test_BoW_reduced)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-25T13:43:47.204117Z","iopub.status.busy":"2023-05-25T13:43:47.202586Z","iopub.status.idle":"2023-05-25T13:43:47.444677Z","shell.execute_reply":"2023-05-25T13:43:47.443417Z","shell.execute_reply.started":"2023-05-25T13:43:47.204039Z"},"papermill":{"duration":0.489598,"end_time":"2023-05-08T06:26:30.391147","exception":false,"start_time":"2023-05-08T06:26:29.901549","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rating</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9503843</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3676359</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6736987</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6916831</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9458520</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8771102</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6947729</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9539166</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8480745</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9977293</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>49999 rows × 1 columns</p>\n","</div>"],"text/plain":["         rating\n","id             \n","9503843       1\n","3676359       1\n","6736987       0\n","6916831       1\n","9458520       1\n","...         ...\n","8771102       0\n","6947729       1\n","9539166       0\n","8480745       0\n","9977293       0\n","\n","[49999 rows x 1 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["submit = pd.read_csv(\"/kaggle/input/2023-ml-project1/sample_submission.csv\", index_col=0)\n","# TEST 데이터에 대한 예측 값을 csv로 저장하는 코드 작성\n","submit['rating'] = y_test_pred\n","submit.to_csv(\"submit.csv\", header=True, mode='w')\n","submit\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.301876,"end_time":"2023-05-08T06:26:30.999594","exception":false,"start_time":"2023-05-08T06:26:30.697718","status":"completed"},"tags":[]},"source":["## \\[Empty Module #8\\] TF-IDF 적용\n","- BoW에서는 고려하지 않는 각 단어들의 중요도를 고려하기 위해, TF-IDF를 적용해봅시다.\n","- 캐글 프로젝트 설명 페이지의 설명을 참고하여 빈칸을 채워, TF-IDF를 구현해봅시다."]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-25T13:56:12.394673Z","iopub.status.busy":"2023-05-25T13:56:12.394202Z","iopub.status.idle":"2023-05-25T13:56:16.922773Z","shell.execute_reply":"2023-05-25T13:56:16.921027Z","shell.execute_reply.started":"2023-05-25T13:56:12.394639Z"},"papermill":{"duration":0.995899,"end_time":"2023-05-08T06:26:32.302887","exception":false,"start_time":"2023-05-08T06:26:31.306988","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["##########################################################################################\n","# Empty Module #8\n","# 빈칸을 적절히 채워넣어 TF-IDF를 위한 Inverse Document Frequency를 계산해봅시다.\n","##########################################################################################\n","N = len(x_train_BoW)  # 총 데이터 샘플의 수\n","\n","\n","def calculate_document_frequency(x):\n","    # 어떤 단어가 등장하는 데이터 샘플(문서)의 수(DF)를 계산하는 코드 작성\n","    document_frequency = np.where(x > 0, 1, 0)\n","    return document_frequency.sum(axis=0)\n","\n","def calculate_inverse_document_frequency(document_frequency):\n","    # DF에 반비례하는 IDF를 계산하는 코드 작성\n","    global N\n","    return np.log(N / (np.ones(len(document_frequency)) + document_frequency))\n","\n","document_frequency = calculate_document_frequency(x_train_BoW) # 여기에 코드 작성\n","inverse_document_frequency = calculate_inverse_document_frequency(document_frequency) # 여기에 코드 작성"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train_tfidf = x_train_BoW * inverse_document_frequency"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-25T13:08:17.493425Z","iopub.status.busy":"2023-05-25T13:08:17.493001Z"},"papermill":{"duration":1.56492,"end_time":"2023-05-08T06:26:34.1783","exception":false,"start_time":"2023-05-08T06:26:32.61338","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# 데이터에 위에서 구한 IDF를 곱하는 코드 작성\n","x_train_tfidf = np.array([x * inverse_document_frequency for x in x_train_BoW])"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.302103,"end_time":"2023-05-08T06:26:34.784772","exception":false,"start_time":"2023-05-08T06:26:34.482669","status":"completed"},"tags":[]},"source":["## \\[Empty Module #9\\]  분류 수행 및 제출: TF-IDF\n","- TF-IDF를 적용한 결과를 기록하여 Kaggle에 제출해봅시다!"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":50.621027,"end_time":"2023-05-08T06:27:25.711221","exception":false,"start_time":"2023-05-08T06:26:35.090194","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["##########################################################################################\n","# Empty Module #9\n","# TEST 데이터에 TF-IDF를 적용하여 모델을 학습, 예측을 수행하고 kaggle에 제출해봅시다.\n","# 이때, BoW와 같은 모델을 사용하여 성능을 비교해봅시다.\n","##########################################################################################\n","\n","# 분류기 정의 및 학습 수행 코드 작성\n","model_tfidf = LogisticRegression(random_state=seed)\n","model_tfidf.fit(x_train_tfidf, y_train)\n","# print(model_tfidf.score(x_train_tfidf))"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":1.234079,"end_time":"2023-05-08T06:27:28.588531","exception":false,"start_time":"2023-05-08T06:27:27.354452","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# TEST 데이터를 전처리하는 코드 작성\n","N = len(x_test_BoW)\n","\n","document_frequency = calculate_document_frequency(x_test_BoW)\n","inverse_document_frequency = calculate_inverse_document_frequency(document_frequency)\n","\n","x_test_tfidf = x_test_BoW * inverse_document_frequency"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.569811,"end_time":"2023-05-08T06:27:29.46472","exception":false,"start_time":"2023-05-08T06:27:28.894909","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# 예측을 수행하는 코드 작성\n","y_test_tfidf_pred = model_tfidf.predict(x_test_tfidf)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.401319,"end_time":"2023-05-08T06:27:30.302375","exception":false,"start_time":"2023-05-08T06:27:29.901056","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["submit_2 = pd.read_csv(\"/kaggle/input/2023-ml-project1/sample_submission.csv\", index_col=0)\n","# TEST 데이터에 대한 예측 값을 csv로 저장하는 코드 작성\n","submit_2['rating'] = y_test_tfidf_pred\n","submit_2.to_csv(\"submit_2.csv\", header=True, mode='w')\n","submit_2"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 결과 비교 TIP\n","- BoW와 TF-IDF에 같은 모델을 적용하여 성능의 차이를 비교해봅시다.\n","- 각각의 방법론에 여러가지 모델을 적용하며, 사용한 방법에 따라 더 적절한 모델이 있는지 고려해봅시다.\n","- 실험 결과들을 토대로, 왜 이런 결과가 도출되었는지 고민해봅시다."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
